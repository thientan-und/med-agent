# ğŸ¥ RAG-Enhanced Medical AI with Doctor Approval (à¸£à¸°à¸šà¸š AI à¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œà¸—à¸µà¹ˆà¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¸”à¹‰à¸§à¸¢ RAG à¹à¸¥à¸°à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸±à¸•à¸´à¸ˆà¸²à¸à¹à¸à¸—à¸¢à¹Œ)

à¹à¸­à¸›à¸à¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œà¸ªà¸³à¸«à¸£à¸±à¸šà¸œà¸¹à¹‰à¸ªà¸¹à¸‡à¸­à¸²à¸¢à¸¸à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡ RAG-LLM Hybrid à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡ à¸à¸£à¹‰à¸­à¸¡à¸£à¸°à¸šà¸š Doctor Approval Workflow, Context-Aware Diagnosis à¹à¸¥à¸° Multi-Model AI Coordination à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹à¸¥à¸°à¸ à¸²à¸©à¸²à¸–à¸´à¹ˆà¸™à¹„à¸—à¸¢

## ğŸŒŸ à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸«à¸¥à¸±à¸ (Key Features)

### ğŸ‘µ RAG-Enhanced Medical AI for Elderly Users
- **ğŸ“š Knowledge-Based Recommendations**: à¹ƒà¸Šà¹‰à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ 55 à¸à¸²à¸£à¸£à¸±à¸à¸©à¸², 19 à¸¢à¸² à¹à¸¥à¸° 42 à¸à¸²à¸£à¸§à¸´à¸™à¸´à¸ˆà¸‰à¸±à¸¢à¸—à¸µà¹ˆà¸„à¸±à¸”à¸ªà¸£à¸£à¹à¸¥à¹‰à¸§
- **ğŸ¤– Hybrid RAG-LLM System**: RAG à¹ƒà¸«à¹‰à¸Šà¸·à¹ˆà¸­à¸¢à¸²à¹à¸¥à¸°à¸›à¸£à¸´à¸¡à¸²à¸“, LLM à¹ƒà¸«à¹‰à¸£à¸°à¸¢à¸°à¹€à¸§à¸¥à¸²à¹à¸¥à¸°à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸²à¸‡à¸„à¸¥à¸´à¸™à¸´à¸
- **ğŸ‘¨â€âš•ï¸ Doctor Approval Required**: à¹à¸à¸—à¸¢à¹Œà¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¸°à¸­à¸™à¸¸à¸¡à¸±à¸•à¸´à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸‚à¸­à¸‡ AI à¸à¹ˆà¸­à¸™à¸ªà¹ˆà¸‡à¹ƒà¸«à¹‰à¸œà¸¹à¹‰à¸›à¹ˆà¸§à¸¢
- **ğŸ“‹ Auto Context Extraction**: à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸œà¸¹à¹‰à¸›à¹ˆà¸§à¸¢ (à¸­à¸²à¸¢à¸¸, à¹€à¸à¸¨, à¸›à¸£à¸°à¸§à¸±à¸•à¸´) à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- **ğŸ”„ Complete Workflow**: à¸œà¸¹à¹‰à¸›à¹ˆà¸§à¸¢ â†’ à¸à¸²à¸£à¸§à¸´à¸™à¸´à¸ˆà¸‰à¸±à¸¢ LLM â†’ à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¸”à¹‰à¸§à¸¢ RAG â†’ à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸±à¸•à¸´à¸‚à¸­à¸‡à¹à¸à¸—à¸¢à¹Œ

### ğŸ¤– Multi-Model AI Architecture
- **ğŸ—£ï¸ à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¸–à¸´à¹ˆà¸™à¹„à¸—à¸¢**: à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸ à¸²à¸©à¸²à¸–à¸´à¹ˆà¸™à¹€à¸«à¸™à¸·à¸­ à¸­à¸µà¸ªà¸²à¸™ à¹ƒà¸•à¹‰ à¹à¸¥à¸°à¸ à¸²à¸„à¸à¸¥à¸²à¸‡
- **ğŸ”„ Translation Pipeline 4 à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™**: Thai â†’ SeaLLM â†’ MedLlama2 â†’ SeaLLM â†’ Thai
- **ğŸ¥ Specialized Medical AI Models**:
  - **MedLlama2** (`medllama2:latest`) à¸ªà¸³à¸«à¸£à¸±à¸šà¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œ
  - **SeaLLM-7B-v2** (`nxphi47/seallm-7b-v2-q4_0:latest`) à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸›à¸¥à¸ à¸²à¸©à¸²à¹„à¸—à¸¢-à¸­à¸±à¸‡à¸à¸¤à¸©
- **ğŸ›ï¸ Model Routing Logic**: à¹€à¸¥à¸·à¸­à¸à¹‚à¸¡à¹€à¸”à¸¥à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸‡à¸²à¸™ (à¸à¸²à¸£à¹à¸›à¸¥ vs à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œ)

### ğŸ“‹ Structured Medical Output
- **DiagnosisCard Schema**: à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹à¸šà¸šà¸¡à¸²à¸•à¸£à¸à¸²à¸™
- **Medical Calculators**: HEART Score, PERC Rule, Wells PE Score à¸à¸£à¹‰à¸­à¸¡à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Input
- **Treatment Guidelines**: à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸à¸²à¸£à¸£à¸±à¸à¸©à¸²à¸•à¹‰à¸­à¸‡à¸¡à¸µ Guideline Citations
- **Uncertainty Metrics**: à¹à¸ªà¸”à¸‡à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¹à¸™à¹ˆà¸™à¸­à¸™à¹à¸¥à¸°à¹€à¸«à¸•à¸¸à¸œà¸¥à¹ƒà¸™à¸à¸²à¸£ Abstain

### ğŸ›¡ï¸ Advanced Safety Systems
- **âš•ï¸ Medical Diagnostic Principles**: à¹ƒà¸Šà¹‰à¸«à¸¥à¸±à¸ OPQRST à¹ƒà¸™à¸à¸²à¸£à¸‹à¸±à¸à¸›à¸£à¸°à¸§à¸±à¸•à¸´
- **ğŸš¨ Emergency Detection**: à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸„à¸³à¸«à¸¥à¸±à¸à¸‰à¸¸à¸à¹€à¸‰à¸´à¸™à¸«à¸¥à¸²à¸¢à¸ à¸²à¸©à¸²à¸–à¸´à¹ˆà¸™à¹à¸¥à¸° Escalate à¸—à¸±à¸™à¸—à¸µ
- **ğŸ” Red Flag Detection**: à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸­à¸²à¸à¸²à¸£à¹€à¸•à¸·à¸­à¸™à¸ à¸±à¸¢à¹à¸¥à¸°à¸ªà¹ˆà¸‡à¸•à¹ˆà¸­à¹à¸à¸—à¸¢à¹Œ
- **ğŸ¯ Conservative Abstention**: à¸«à¸¥à¸µà¸à¹€à¸¥à¸µà¹ˆà¸¢à¸‡à¸à¸²à¸£à¸§à¸´à¸™à¸´à¸ˆà¸‰à¸±à¸¢à¹€à¸¡à¸·à¹ˆà¸­à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸à¸µà¸¢à¸‡à¸à¸­

## ğŸ—£ï¸ à¸ à¸²à¸©à¸²à¸–à¸´à¹ˆà¸™à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š (Supported Thai Dialects)

### à¸ à¸²à¸„à¹€à¸«à¸™à¸·à¸­ (Northern)
- à¸ˆà¸¸à¸, à¸ˆà¸¸à¸à¹à¸¥à¹‰à¸§ â†’ à¸›à¸§à¸”, à¸›à¸§à¸”à¸¡à¸²à¸
- à¹à¸«à¸‡, à¹à¸«à¸‡à¹à¸¥à¹‰à¸§ â†’ à¸›à¸§à¸”, à¸›à¸§à¸”à¸¡à¸²à¸

### à¸ à¸²à¸„à¸­à¸µà¸ªà¸²à¸™ (Isan)
- à¹à¸¥à¹‰à¸‡, à¹à¸¥à¹‰à¸‡à¹‚à¸à¸” â†’ à¸›à¸§à¸”, à¸›à¸§à¸”à¸¡à¸²à¸
- à¸šà¸±à¸à¹à¸¥à¹‰à¸§à¹‚à¸à¸” â†’ à¸¡à¸²à¸à¸ˆà¸£à¸´à¸‡à¹†
- à¸«à¸·à¹ˆà¸­ â†’ à¸­à¸°à¹„à¸£

### à¸ à¸²à¸„à¹ƒà¸•à¹‰ (Southern)
- à¸›à¸§à¸”à¸«à¸±à¸‡, à¹€à¸ˆà¹‡à¸šà¸«à¸±à¸‡ â†’ à¸›à¸§à¸”à¸«à¸±à¸§, à¹€à¸ˆà¹‡à¸šà¸«à¸±à¸§
- à¹‚à¸à¸”à¸«à¸±à¸‡ â†’ à¸¡à¸²à¸
- à¹à¸”à¸ â†’ à¸à¸´à¸™

## ğŸ”„ RAG-LLM Hybrid Medical Pipeline

```
1. Thai Input + Auto Context Extraction
   â†“
2. Patient Demographics â†’ Extract age, gender, medical history from Thai text
   â†“
3. SeaLLM-7B-v2 Translation â†’ English symptoms
   â†“
4. Emergency Detection â†’ Check for critical symptoms ('à¸¡à¸¶à¸™à¸‡à¸‡', etc.)
   â†“
5. LLM Medical Analysis (MedLlama2) â†’ Generate primary diagnosis
   â†“
6. RAG Knowledge Retrieval â†’ Find medicines and dosages from 55 treatments/19 medicines
   â†“
7. LLM Enhancement â†’ Generate duration, frequency, clinical instructions
   â†“
8. Hybrid Response Creation â†’ Combine RAG medicines + LLM clinical reasoning
   â†“
9. Doctor Approval Queue â†’ Complete AI response awaits physician review
   â†“
10. Doctor Actions â†’ Approve, Edit, or Reject AI recommendations
   â†“
11. Final Response to Patient:
    â€¢ Complete medication guidance (RAG + LLM)
    â€¢ Doctor-approved recommendations
    â€¢ Emergency escalation when needed
    â€¢ Clear status updates
```

## ğŸ›¡ï¸ Multi-Layer Safety Architecture

### RAG-LLM Safety Systems
- **ğŸ‘¨â€âš•ï¸ Doctor Approval Required**:
  - All AI responses must be approved by qualified physicians
  - Complete audit trail of AI decisions and doctor modifications
  - Three-step workflow: Approve, Edit, or Reject AI recommendations
- **ğŸ“š Evidence-Based RAG**:
  - Medicine recommendations from curated knowledge base (55 treatments, 19 medicines)
  - Contraindication checking based on patient demographics
  - Safety guidelines integrated into medication retrieval
- **ğŸ¤– LLM Clinical Reasoning**:
  - Duration and instructions generated by MedLlama2 with safety considerations
  - Patient context integration (age, gender, medical history)
  - Conservative escalation for emergency symptoms

### Traditional Safety Features
- **à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸„à¸³à¸ªà¸™à¸—à¸™à¸²à¸—à¸±à¹ˆà¸§à¹„à¸›**: à¹à¸¢à¸ greeting à¹à¸¥à¸°à¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›à¸­à¸­à¸à¸ˆà¸²à¸à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œ
- **à¸à¸²à¸£à¸‚à¸­à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡**: à¸«à¸²à¸à¸­à¸²à¸à¸²à¸£à¹„à¸¡à¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™ (à¹€à¸Šà¹ˆà¸™ "à¹„à¸¡à¹ˆà¸ªà¸šà¸²à¸¢") à¸ˆà¸°à¸‚à¸­à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‰à¸à¸²à¸°à¹€à¸ˆà¸²à¸°à¸ˆà¸‡
- **à¸«à¸¥à¸±à¸ OPQRST**: à¹ƒà¸Šà¹‰à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸‹à¸±à¸à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œà¸¡à¸²à¸•à¸£à¸à¸²à¸™
- **à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹€à¸«à¸•à¸¸à¸‰à¸¸à¸à¹€à¸‰à¸´à¸™**: à¸£à¸­à¸‡à¸£à¸±à¸šà¸„à¸³à¸‰à¸¸à¸à¹€à¸‰à¸´à¸™à¸«à¸¥à¸²à¸¢à¸ à¸²à¸©à¸²à¸–à¸´à¹ˆà¸™
- **à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¸™à¸²à¸”à¸¢à¸²à¹€à¸‰à¸à¸²à¸°à¹€à¸ˆà¸²à¸°à¸ˆà¸‡**: à¸£à¸°à¸šà¸¸à¹€à¸‰à¸à¸²à¸°à¸›à¸£à¸°à¹€à¸ à¸—à¸¢à¸²à¸—à¸±à¹ˆà¸§à¹„à¸›
- **à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸›à¸à¸´à¹€à¸ªà¸˜à¸„à¸§à¸²à¸¡à¸£à¸±à¸šà¸œà¸´à¸”à¸Šà¸­à¸š**: à¹à¸ªà¸”à¸‡à¸Šà¸±à¸”à¹€à¸ˆà¸™à¹ƒà¸™à¸—à¸¸à¸à¸„à¸³à¸•à¸­à¸š

## Setup

### 1. **Install Dependencies**:
```bash
cd medical-chat-app
pnpm install
```

### 2. **Install and Setup Ollama**:
```bash
# Install Ollama
./setup-ollama.sh

# Download required models (~8GB total)
./setup-models.sh
```

### 3. **Environment Setup**:
```bash
# Create .env.local
echo "OLLAMA_URL=http://localhost:11434" > .env.local
```

### 4. **Test AI Models**:
```bash
# Test all integrations
node test-llm.js
```

### 5. **Run Development Server**:
```bash
pnpm dev
```

### 6. **Open Application**:
Open [http://localhost:3000](http://localhost:3000) in your browser

## Project Structure

```
medical-chat-app/
â”œâ”€â”€ frontend/                      # Next.js frontend application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/route.ts      # Chat API with dialect normalization
â”‚   â”‚   â”‚   â””â”€â”€ summary/route.ts   # Summary generation API
â”‚   â”‚   â””â”€â”€ page.tsx               # Main application page
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ChatInterface.tsx      # Main chat component
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ ollama-client.ts       # Ollama/MedLlama2 integration
â”‚   â”‚   â”œâ”€â”€ seallm-translator.ts   # Thai-English translation service
â”‚   â”‚   â”œâ”€â”€ thai-dialect-helper.ts # Thai dialect normalization
â”‚   â”‚   â””â”€â”€ medical-prompts.ts     # Medical prompts and safety
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ chat.ts                # TypeScript types
â””â”€â”€ backend/                       # FastAPI backend with precision architecture
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ core/                  # Precision-oriented components
    â”‚   â”‚   â”œâ”€â”€ types.py           # Pydantic schemas (DiagnosisCard, etc.)
    â”‚   â”‚   â”œâ”€â”€ router.py          # Evidence-first routing system
    â”‚   â”‚   â”œâ”€â”€ calculators.py     # Medical calculators (HEART, PERC, Wells)
    â”‚   â”‚   â”œâ”€â”€ critic.py          # Blocking precision critic
    â”‚   â”‚   â”œâ”€â”€ uncertainty.py     # Uncertainty quantification
    â”‚   â”‚   â””â”€â”€ precision_service.py # Main precision orchestrator
    â”‚   â”œâ”€â”€ services/
    â”‚   â”‚   â”œâ”€â”€ ollama_client.py   # Real Ollama client for multi-model
    â”‚   â”‚   â””â”€â”€ medical_ai_service.py # Medical AI service
    â”‚   â””â”€â”€ api/
    â”‚       â””â”€â”€ v1/
    â”‚           â””â”€â”€ medical/       # Precision medical APIs
    â””â”€â”€ requirements.txt           # Python dependencies
```

## AI Models

### Local Models via Ollama

1. **MedLlama2** (3.8GB)
   - Medical-specialized LLM
   - Provides structured medical assessments
   - Follows diagnostic principles

2. **SeaLLM-7B-v2-Q4** (4.2GB)
   - Southeast Asian language model
   - Thai-English bidirectional translation
   - Preserves medical terminology accuracy

## Medical Diagnostic Principles

### OPQRST Method for Pain Assessment
- **O**nset: When did it start?
- **P**rovocation/Palliation: What makes it better/worse?
- **Q**uality: What does it feel like?
- **R**egion/Radiation: Where is it located?
- **S**everity: Scale 1-10
- **T**ime: How long has it been?

### Information Gathering
- Vague symptoms ("à¹„à¸¡à¹ˆà¸ªà¸šà¸²à¸¢", "feeling unwell") trigger specific questions
- Follows proper medical history-taking principles
- Never diagnoses based on insufficient information

## à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸›à¸à¸´à¹€à¸ªà¸˜à¸„à¸§à¸²à¸¡à¸£à¸±à¸šà¸œà¸´à¸”à¸Šà¸­à¸šà¸—à¸µà¹ˆà¸ªà¸³à¸„à¸±à¸ (Important Disclaimers)

âš ï¸ **à¸‚à¹‰à¸­à¸ˆà¸³à¸à¸±à¸”à¸„à¸§à¸²à¸¡à¸£à¸±à¸šà¸œà¸´à¸”à¸Šà¸­à¸šà¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œ**: à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢ AI à¸™à¸µà¹‰à¹ƒà¸«à¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸¸à¸‚à¸ à¸²à¸à¸—à¸±à¹ˆà¸§à¹„à¸›à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸à¸£à¸¸à¸“à¸²à¸›à¸£à¸¶à¸à¸©à¸²à¸œà¸¹à¹‰à¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸à¸”à¹‰à¸²à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¹à¸™à¸°à¸™à¸³ à¸à¸²à¸£à¸§à¸´à¸™à¸´à¸ˆà¸‰à¸±à¸¢ à¸«à¸£à¸·à¸­à¸à¸²à¸£à¸£à¸±à¸à¸©à¸²à¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œà¹€à¸ªà¸¡à¸­

âš ï¸ **à¹€à¸«à¸•à¸¸à¸‰à¸¸à¸à¹€à¸‰à¸´à¸™**: à¸«à¸²à¸à¸„à¸¸à¸“à¸›à¸£à¸°à¸ªà¸šà¹€à¸«à¸•à¸¸à¸‰à¸¸à¸à¹€à¸‰à¸´à¸™à¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œ à¹‚à¸—à¸£à¸«à¸²à¸šà¸£à¸´à¸à¸²à¸£à¸‰à¸¸à¸à¹€à¸‰à¸´à¸™ (1669) à¸—à¸±à¸™à¸—à¸µ

âš ï¸ **à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¹à¸à¸—à¸¢à¹Œ**: à¹à¸­à¸›à¸à¸¥à¸´à¹€à¸„à¸Šà¸±à¸™à¸™à¸µà¹‰à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¸ªà¸´à¹ˆà¸‡à¸—à¸”à¹à¸—à¸™à¸„à¸³à¹à¸™à¸°à¸™à¸³ à¸à¸²à¸£à¸§à¸´à¸™à¸´à¸ˆà¸‰à¸±à¸¢ à¸«à¸£à¸·à¸­à¸à¸²à¸£à¸£à¸±à¸à¸©à¸²à¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œà¸ˆà¸²à¸à¸œà¸¹à¹‰à¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸

âš ï¸ **à¹€à¸‰à¸à¸²à¸°à¸à¸²à¸£à¸¨à¸¶à¸à¸©à¸²**: à¹‚à¸„à¸£à¸‡à¸à¸²à¸£à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¹€à¸à¸µà¸¢à¸‡à¸à¸²à¸£à¸à¸´à¸ªà¸¹à¸ˆà¸™à¹Œà¹à¸™à¸§à¸„à¸§à¸²à¸¡à¸„à¸´à¸” (POC) à¹€à¸à¸·à¹ˆà¸­à¸à¸²à¸£à¸¨à¸¶à¸à¸©à¸²à¹à¸¥à¸°à¸à¸²à¸£à¸ªà¸²à¸˜à¸´à¸•à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™

## Development Commands

```bash
# Development
pnpm dev          # Start dev server (port 3000)
pnpm build        # Production build
pnpm start        # Start production server
pnpm lint         # Run ESLint checks

# Testing
node test-llm.js  # Test AI model integrations

# Model Management
ollama list       # List loaded models
ollama serve      # Start Ollama server
```

## Technology Stack

- **Frontend**: Next.js 15, TypeScript, Tailwind CSS
- **AI Runtime**: Ollama (local model hosting)
- **Medical Model**: MedLlama2 (quantized GGUF)
- **Translation**: SeaLLM-7B-v2 (Thai-English)
- **Icons**: Lucide React

## License

This project is for educational and demonstration purposes only.
